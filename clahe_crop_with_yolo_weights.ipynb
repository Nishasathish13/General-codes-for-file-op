{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Data/Muzzle_Images/Clean_2000_to_3100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy import spatial\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "from sklearn.neighbors.unsupervised import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from torchvision.transforms.functional import to_tensor,to_pil_image\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import time\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import copy\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/drive/My Drive/Rakesh/Muzzle_Similarity/Muzzle_Detection\")\n",
    "\n",
    "from numpy import random\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import  LoadImages\n",
    "from utils.general import (check_img_size, non_max_suppression,  plot_one_box, scale_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_muzzle(source=\"/content/drive/MyDrive/Data/Muzzle_Images/Clean_2000_to_3100/raw_images/test\", weights = \"weights/last.pt\", conf_thres=0.4, iou_thres=0.5, view_img=0, imgsz=416, device_name=\"cpu\"):\n",
    "\n",
    "    # Initialize\n",
    "    device = torch.device(device_name)\n",
    "\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "\n",
    "    # Set Dataloader\n",
    "    dataset = LoadImages(source, img_size=imgsz)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "    # Run inference\n",
    "    actual_cord = []\n",
    "    found = False\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        pred = model(img, augment=False)[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False)\n",
    "\n",
    "        # Process detections\n",
    "        \n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            p, s, im0 = path, '', im0s\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "                tlbr = det[:, :4].cpu().numpy().astype(int)[0] # top-left, bottom-right\n",
    "\n",
    "                actual_cord.append(tlbr)\n",
    "                found =  True\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if view_img:  # Add bbox to image\n",
    "                        label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "\n",
    "            # Stream results\n",
    "            if view_img:\n",
    "                vis_image = cv2.resize(im0, (imgsz, imgsz))\n",
    "                if tlbr[0] != None:\n",
    "                    muzzle_image = cv2.resize(im0[tlbr[1]:tlbr[3], tlbr[0]:tlbr[2]], (imgsz, imgsz))\n",
    "                    vis_image = np.concatenate((vis_image, muzzle_image), axis=1)\n",
    "                \n",
    "                plt.imshow(vis_image)\n",
    "                plt.title('Semi-Crop                Fully Cropped')\n",
    "\n",
    "                tlbr = [None]\n",
    "                if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "                    raise StopIteration\n",
    "\n",
    "    return found, actual_cord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaheTransform(object):\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        :param img: PIL Raw Image \n",
    "\n",
    "        :return: CLAHE image\n",
    "        \"\"\"\n",
    "        img = np.asarray(img)\n",
    "        img_dtype = img.dtype\n",
    "        img = img.astype(np.uint8)\n",
    "        #-----Converting image to LAB Color model----------------------------------- \n",
    "        lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "        #-----Splitting the LAB image to different channels-------------------------\n",
    "        l, a, b = cv2.split(lab)\n",
    "\n",
    "        #-----Applying CLAHE to L-channel-------------------------------------------\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        cl = clahe.apply(l)\n",
    "\n",
    "        #-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "        limg = cv2.merge((cl,a,b))\n",
    "\n",
    "        #-----Converting image from LAB Color model to RGB model--------------------\n",
    "        final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "        clahe_img = final.astype(img_dtype)\n",
    "\n",
    "        return Image.fromarray(clahe_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe_crop(imagefile):\n",
    "    \n",
    "    \n",
    "    img=Image.open(imagefile)\n",
    "    \n",
    "    # Apply CLAHE Transform\n",
    "    clh_transforms = transforms.Compose([ClaheTransform()])\n",
    "    img = clh_transforms(img)\n",
    "    \n",
    "    #Detect Muzzle\n",
    "    found, coord = detect_muzzle(source=imagefile, weights=\"/content/drive/My Drive/Rakesh/Muzzle_Similarity/Muzzle_Detection/weights/last.pt\")\n",
    "    if found:\n",
    "        coord  = coord[0]\n",
    "        top    = coord[1]\n",
    "        left   = coord[0]\n",
    "        height = coord[3] - coord[1]\n",
    "        width  = coord[2] - coord[0]\n",
    "        img = transforms.functional.crop(img, top, left, height, width)\n",
    "\n",
    "#     # Apply Default Transform\n",
    "    def_transforms = transforms.Compose([\n",
    "                                    transforms.Resize((224,224)),\n",
    "#                                     transforms.ToTensor(),\n",
    "#                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),# Image Net\n",
    "#                                     transforms.ToPILImage()\n",
    "                                    ])\n",
    "    img = def_transforms(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2raw = \"/content/drive/MyDrive/Data/Muzzle_Images/yolo_field_laptop/multiple_mobile_testing/laptop/images_test\"\n",
    "filenames = []\n",
    "for (dirpath, dirnames, files) in os.walk(path2raw):      \n",
    "    filenames += [os.path.join(dirpath, file) for file in files]\n",
    "\n",
    "\n",
    "for file in filenames:\n",
    "    full_crop_img = full_crop(file)\n",
    "    save_path = file.replace(\"images_test\", \"images_test_full_crop\")\n",
    "    full_crop_img.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2093d742d7d1cb9418d3fbeed24799d6d160b43067b0f237e97a0b5a3f2944a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mlep-w1-lab': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
